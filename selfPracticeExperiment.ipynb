{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "dc13a45ed11b1b662b77e117ddacdf75f2a8b689ef2fab88ed5800283a7fb6af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
    "file_name = \"horse-or-human.zip\"\n",
    "training_dir = 'horse-or-human/training/'\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "zip_ref.extractall(training_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\"\n",
    "\n",
    "validation_file_name = \"validation-horse-or-human.zip\"\n",
    "validation_dir = 'horse-or-human/validation/'\n",
    "\n",
    "urllib.request.urlretrieve(validation_url, validation_file_name)\n",
    "zip_ref = zipfile.ZipFile(validation_file_name, 'r')\n",
    "zip_ref.extractall(validation_dir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1027 images belonging to 2 classes.\nFound 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "training_datagen = tf.keras.preprocessing.image.ImageDataGenerator(1./255)\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(1./255)\n",
    "\n",
    "training_gen = training_datagen.flow_from_directory(\n",
    "    training_dir, \n",
    "    target_size = (300, 300),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "#class_mode would be set to 'categorical' if it was a multi-classification problem\n",
    "\n",
    "    #train_datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,\n",
    "    #rotation_range=40,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #shear_range=0.2,\n",
    "    #zoom_range=0.2,\n",
    "    #horizontal_flip=True,\n",
    "    #fill_mode='nearest'\n",
    "    )#\n",
    "\n",
    "validation_gen = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (300, 300),\n",
    "    batch_size = 32, \n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 298, 298, 64)      1792      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 149, 149, 64)      0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 147, 147, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 73, 73, 64)        0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 71, 71, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 35, 35, 32)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 33, 33, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 14, 14, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_10 (MaxPooling (None, 7, 7, 64)          0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 5, 5, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_11 (MaxPooling (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               131584    \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 286,250\nTrainable params: 286,250\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu, input_shape = (300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "optimizer = tf.keras.optimizers.RMSprop(lr = 0.001), metrics = ['accuracy']) #set to categorical crossentropy for multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "class myCallback1(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"/nReached 95% accuracy so stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks1 =  myCallback1()\n",
    "\n",
    "class myCallback2(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('accuracy')>0.99):\n",
    "            print(\"/nReached 99% accuracy, therefore, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks2 = myCallback2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "model.fit_generator(training_gen, validation_gen, epoch = epochs, callbacks=[callbacks2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(img_path, target_size = (300, 300))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "image_tensor = np.vstack([x])\n",
    "class = model.predict(image_tensor)\n",
    "\n",
    "if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "    else:\n",
    "    print(fn + \" is a horse\")"
   ]
  }
 ]
}