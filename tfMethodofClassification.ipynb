{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "62777786f8687b9575c0619f17c497edf6c2b58eb2992f0dd825a023781db6e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import PIL\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.models import Sequential"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pathlib\r\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\r\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\r\n",
    "data_dir = pathlib.Path(data_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size, img_height, img_width = 64, 180, 180\r\n",
    "\r\n",
    "training_dir = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    directory = data_dir,\r\n",
    "    validation_split = 0.2,\r\n",
    "    subset = \"training\",\r\n",
    "    seed = 123,\r\n",
    "    image_size = (img_height, img_width),\r\n",
    "    batch_size = batch_size)\r\n",
    "\r\n",
    "validation_dir = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    directory = data_dir,\r\n",
    "    validation_split = 0.2,\r\n",
    "    subset = \"validation\",\r\n",
    "    seed = 123,\r\n",
    "    image_size = (img_height, img_width),\r\n",
    "    batch_size = batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_training_dir(directory, batch_size, img_height, img_width, validation_split, seed):\r\n",
    "    training_dir = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        directory = directory,\r\n",
    "        validation_split = validation_split,\r\n",
    "        image_size = (img_height, img_width),\r\n",
    "        subset = \"training\",\r\n",
    "        seed = seed,\r\n",
    "        batch_size = batch_size)\r\n",
    "    return training_dir\r\n",
    "\r\n",
    "def get_validation_dir(directory, batch_size, img_height, img_width, validation_split, seed):\r\n",
    "    validation_dir = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        directory = directory,\r\n",
    "        validation_split = validation_split,\r\n",
    "        image_size = (img_height, img_width),\r\n",
    "        batch_size = batch_size,\r\n",
    "        seed = seed,\r\n",
    "        subset = \"validation\")\r\n",
    "    return validation_dir \r\n",
    "\r\n",
    "training_dir = get_training_dir(data_dir, 64, 180, 180, 0.2, 123)\r\n",
    "validation_dir = get_validation_dir(data_dir, 64, 180, 180, 0.2, 123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class_names = training_dir.class_names\r\n",
    "print(\"There are:\", len(class_names), \"classes \\nand their names are: \", class_names)\r\n",
    "\r\n",
    "for images, labels in training_dir:\r\n",
    "    print(images.shape)\r\n",
    "    print(labels.shape)\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#prefetch overlaps data preprocessing and model execution while training.\r\n",
    "#cache keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\r\n",
    "\r\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "training_dir = training_dir.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\r\n",
    "validation_dir = validation_dir.cache().prefetch(buffer_size = AUTOTUNE)\r\n",
    "\r\n",
    "normalizing_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\r\n",
    "normalized_ds = training_dir.map(lambda x, y: (normalizing_layer(x), y))\r\n",
    "\r\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\r\n",
    "first_image = image_batch[0]\r\n",
    "\r\n",
    "# Notice the pixels values are now in `[0,1]`.\r\n",
    "print(np.min(first_image), np.max(first_image))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_classes = len(class_names)\r\n",
    "\r\n",
    "data_aug = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", \r\n",
    "    input_shape = (img_height, img_width)),\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)])\r\n",
    "\r\n",
    "model = tf.keras.Sequential([\r\n",
    "    data_aug,\r\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "\r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
    "\r\n",
    "    tf.keras.layers.Dropout(0.2),\r\n",
    "    tf.keras.layers.Flatten(),\r\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.Dense(num_classes, activation = tf.nn.softmax)\r\n",
    "])\r\n",
    "\r\n",
    "model = tf.keras.Input()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "training_dir = training_dir.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\r\n",
    "validation_dir = validation_dir.cache().prefetch(buffer_size = AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 10\r\n",
    "history = model.fit(training_dir, validation_data = validation_dir, epochs = epochs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acc = history.history['accuracy']\r\n",
    "val_acc = history.history['val_accuracy']\r\n",
    "\r\n",
    "loss = history.history['loss']\r\n",
    "val_loss = history.history['val_loss']\r\n",
    "\r\n",
    "epochs_range = range(epochs)\r\n",
    "\r\n",
    "plt.figure(figsize = (8, 8))\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "plt.plot(epochs_range, acc, label = \"Training Accuracy\")\r\n",
    "plt.plot(epochs_range, val_acc, label = \"Validation Accuracy\")\r\n",
    "\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "plt.plot(epochs_range, loss, label = \"Training Loss\")\r\n",
    "plt.plot(epochs_range, val_loss, label = \"Validation Loss\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}